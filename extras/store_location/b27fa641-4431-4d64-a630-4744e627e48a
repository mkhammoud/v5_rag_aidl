{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "{Lesson 1: Introduction to Machine Learning}\n\\subsection{Introduction}\nMachine learning (ML) resides under the expansive domain of artificial intelligence (AI). This lesson aims to abstractly explain ML, establishing a foundational understanding before delving into its Python implementation. We'll elaborate on the ML pipeline, model development, and demonstrate Python's application in this context.\n\n\\subsection{Machine Learning Types}\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.7\\linewidth]{image.png}\n    \\label{fig:enter-label}\n\\end{figure}\n\n\nMachine learning involves presenting large datasets to machines, enabling them to learn and perform tasks such as prediction, pattern recognition, or data classification. The primary types include supervised, unsupervised, and reinforcement learning.\n\n\\begin{itemize}\n    \\item Supervised Learning: This type of machine learning model learns from labeled data, where the input data is paired with the corresponding desired output. The algorithm learns to map inputs to outputs, enabling it to make predictions or classify new data. For example, a dataset such as the heart disease dataset where we know each record has a label (i.e., HeartDisease Column). The AI learns statistical patterns out of all of these data in order to be able to tell the potential label of a new record.\n    \\item Unsupervised Learning: This kind of model finds patterns or structures in unlabeled data. They aim to explore and extract insights from data without specific guidance on what to look for. For example, let us say we have a dataset of pictures of cats and dogs. If we want the computer to be able to tell who are the cats and dogs without providing any additional information other than the images (i.e. no labels) then unsupervised learning is used.\n    \\item Reinforcement Learning: We definitely won't focus on this one as it can be too complicated for this course. Briefly, in Reinforcement Learning, algorithms learn by interacting with an environment. They receive feedback in the form of rewards or penalties based on their actions and learn to maximize rewards over time by adapting their strategies. An example would be teaching the computer how to play a game.\n\\end{itemize}\n\n\n\n\n\\subsection{Machine Learning Pipeline}\nBefore implementing ML, a structured pipeline is crucial, ensuring no vital steps are overlooked. Key steps include problem definition, data collection, analysis, cleaning, preprocessing, feature engineering, model selection, dataset splitting, model training, evaluation, and deployment. It is worth mentioning that some steps can be introduced/removed depending on the nature of the problem. \n\\begin{enumerate}\n    \\item Problem Definition: The first step is to definitely being able to define the problem that we are trying to solve. For example, we want to be able to distinguish whether someone has heart disease or not.\n    \\item Data Collection: In this step, we gather the data rows that are necessary to conduct our learning. In some cases, we can simply rely on pre-existing datasets (i.e., like the heart disease dataset).\n    \\item Data Analysis: This step is used throughout the process to show important insights about the datasets, training, and results. Data Visualization can also assist in this phase.   \n    \\item Data Cleaning: We clean the data by handling missing values, duplicated, outliers, etc.\n\n    \\item Data Preprocessing: As previously discussed in the course, we preprocess the data by adopting encoding categorical variables, scaling numerical features, etc.  \n    \\item Feature Engineering: This part is where only the important features are being selected to complete the training. There might exist a dataset with thousands of columns or more. With feature engineering, we can eliminate the non important features which saves us time and resources for completing the training tasks.\n    \\item Model Selection: A lot of machine learning models exist and each one might be suitable for a certain problem. For example, in some cases we might want to use linear regression. In others, we might use neural networks. No need to know more about this process for now.\n    \\item Splitting dataset: usually, we split the dataset into two subsets. The first one is training (used in the training process), and the second one is testing (used to evaluate the trained model)\n    \\item Model Training: After setting up everything, the model will train the first subset of the data.\n    \\item Model Evaluation: We evaluate the model's performance on the testing data using appropriate metrics. We also adjust the model if necessary to improve performance.\n    \\item Model Deployment: The trained model can be finally saved and imported into realworld use cases.\n\n\\end{enumerate}\n\n\\subsection{Model Evaluation and Prediction}\n\nModel evaluation serves as a critical phase where researchers and programmers validate their models. An ideal machine learning model exhibits consistent accuracy in predicting outcomes. Consider the example of predicting heart disease: a high-quality model should consistently and accurately determine whether a person has heart disease. Especially in crucial domains like healthcare, maintaining a high model quality is paramount. Conversely, a poor model delivers inaccurate results frequently, leading to unreliable predictions. \n\nIn supervised learning environments, a common practice to assess model correctness involves evaluating its performance on a testing dataset. Generally speaking, the whole dataset will be split into a training dataset that we shall pass to the model for training, and a testing dataset which we will test the model with. After model training, let's assume we have a dataset of 100 labeled rows. By testing the model's predictions against these known 100 labels, we gauge its accuracy. If all the data were correctly guessed by the model, 'theoretically' we say that it is 100\\% accurate. However, achieving 100\\% accuracy in practical scenarios is challenging due to various influencing factors such as dataset quality, model selection, computational limitations, etc.\n\nThe Prediction Process involves these steps:\n\\begin{itemize}\n    \\item Input Data: Introduce new, unseen data to the trained model.\n    \\item Model Inference/Prediction: The model leverages learned patterns to predict outcomes for the input data.\n    \\item Output: Obtain predicted labels or values from the model for the given inputs.\n\\end{itemize}\n\n\n\n\n\\subsection{Tools and Resources}\nSeveral Python libraries significantly support ML processes. Notably, Scikit-learn, TensorFlow, and PyTorch facilitate model training and generation. The subsequent lesson will explore Scikit-learn, focusing on conducting ML using this library. These kinds of tools allow us to worry less bout the underlying mechanisms of model building. Engineers have crafted these libraries to ease the process of conducting machine learning for Python.\n\n\n\\subsection{Self-evaluation Quiz: Machine Learning Knowledge}\nThis is a Self-evaluation knowledge quiz about Machine Learning. The objective is to ensure that the student comprehends some important aspects of ML before moving forward. \n\n\nQ1- In machine learning, which type of model learns from labeled data?\n- Supervised Learning *\n- Unsupervised Learning\n- Reinforcement Learning\n- Semi-supervised Learning\nFeedback: Supervised learning models learn from labeled data, where input data is paired with corresponding desired outputs for training.\n\nQ2- How does 'model evaluation' contribute to the iterative process of machine learning?\n- It fine-tunes the hyperparameters for better model accuracy\n- It assesses the model's performance on unseen data *\n- It splits the dataset for training and testing purposes\n- It visualizes the relationships between input features\nFeedback: Model evaluation assesses the model's performance on unseen data, helping refine and improve the model in subsequent iterations.\n\nQ3- Which step in the machine learning pipeline involves handling missing values?\n- Data Collection\n- Data Analysis\n- Data Cleaning *\n- Feature Engineering\nFeedback: Handling missing values and outliers is crucial within the machine learning pipeline, known as data cleaning, ensuring data quality.\n\nQ4- What is the purpose of data preprocessing in machine learning?\n- Select important features for training\n- Gather necessary data rows\n- Evaluate the model's performance\n- Encode categorical variables, scale numerical features, etc. *\nFeedback: Data preprocessing involves preparing and transforming raw data, including encoding categorical variables and scaling numerical features for better model performance.\n\nQ5- How is model accuracy typically assessed in supervised learning?\n- Evaluating predictions on the training dataset\n- Evaluating predictions on the testing dataset *\n- Counting the number of features\n- Measuring the number of iterations during training\nFeedback: Model accuracy in supervised learning is typically assessed by evaluating its predictions on a separate testing dataset.\n\nQ6- Which phase in the machine learning pipeline involves splitting the dataset into training and testing subsets?\n- Data Collection\n- Data Cleaning\n- Model Training\n- Dataset Splitting *\nFeedback: Dataset Splitting involves partitioning the dataset into subsets for training the model and evaluating its performance.\n\nQ7- Which libraries are commonly used in Python for machine learning tasks?\n- Scikit-learn, TensorFlow, and PyTorch *\n- NumPy and Pandas\n- Matplotlib and Seaborn\n- Keras and Theano\nFeedback: Commonly used Python libraries for machine learning tasks include Scikit-learn, TensorFlow, and PyTorch, facilitating model building and training.\n\nQ8- What phase in the machine learning pipeline involves selecting a suitable machine learning model?\n- Data Collection\n- Model Selection *\n- Model Training\n- Model Evaluation\nFeedback: Selecting a suitable machine learning model is a pivotal phase within the machine learning pipeline, ensuring the most appropriate model is chosen for the task.\n\nQ9- If a machine learning model predicted 4 out of 5 records correctly after training, theoretically, what would be the accuracy of the model?\n- 20\\%\n- 50\\%\n- 80\\% *\n- 100\\%\nFeedback: 4 out of 5 times is 80\\% of the time.\n\nQ10- What is the primary goal of machine learning model deployment?\n- Training the model\n- Evaluating the model\n- Using the model in real-world applications *\n- Optimizing the model\nFeedback: The primary goal of machine learning model deployment is to apply the trained model to solve real-world problems or scenarios.", "metadata": {"source": "./full-course/aai.txt"}}}