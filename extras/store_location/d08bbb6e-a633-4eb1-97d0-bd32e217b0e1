{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "{Extra Lesson: Linear Regression Using Scikit-Learn}\n\\subsection{Introduction}\nIn this lesson, we will discuss the Linear Regression Model. \\textbf{This part is not required for the course, or the project}. However, it can be general knowledge that should be elaborated in future courses. We will distinguish between Logistic Regression and Linear Regression. Furthermore, we will elaborate on a certain use case application of modeling a Linear Regression model and evaluating its performance.\n\n\\subsection{Linear Regression and Logistic Regression}\nIn Linear Regression, we try to build a line to fit the data (\\textit{X, y}). \nAll you need to know about Linear Regression at this stage is that it is used to predict real values or numbers. If we want to predict classes, like if the patient has a heart disease or not (i.e., binary classification), we will be using the Logistic Regression model (as described above). \\\\ For example, if we are trying to predict the prices of apartments, the value will be a continuous value (numbers), thus, we use linear regression. On the other hand, if we are trying to predict whether a person is female or male, the output is discrete (classes/labels), thus we utilize logistic regression instead.\n\n\\subsection{Linear Regression Model}\n\\subsubsection*{Setting up environment.}\nWe will prepare in this part a randomly generated dataset composed of x and y. You can follow along using your Jupyter Notebook.\n\n\\textbf{\\textit{Now, open a Notebook instance and let us start coding. }}\n\nWe will use the following simple data to build our first ML regression model:\n\n\\begin{lstlisting}[language=Python]\nimport matplotlib.pyplot as plt\nimport numpy as np\nrng = np.random.RandomState(42)\nx = 10 * rng.rand(50)\ny = 2 * x - 1 + rng.randn(50)\nplt.scatter(x, y);\n\\end{lstlisting}\n\nWhat we did in this code was generate a random dataset.\n\nBefore we start, download Scikit-Learn if you don't have it installed using the below. Paste the below code in a notebook cell and run it.\n\\begin{lstlisting}[language=Python]\n!pip install -U scikit-learn\n\\end{lstlisting}\n\n\\textbf{\\textit{Now let's use the recipe outlined earlier to build the Linear Regression model.}}\n\n\\subsubsection*{Choose a class of model.}\nIn Scikit-Learn, every ML model is represented by a Python class (Remember Classes discussed in Week 5). Therefore, to build a Linear Regression model, we would have to import it as follows:\n\\begin{lstlisting}[language=Python]\nfrom sklearn.linear_model import LinearRegression\n\\end{lstlisting}\n\n\\subsubsection*{Choose model hyperparameters.}\nWhen building a model with Scikit-Learn, we have to answer a few questions. As described in Week 5, a model class is different from a model instance. Thus, we can specify some properties (i.e. hyperparameters) for the model we are trying to build. This is possible during the creation of the instance. In Linear regression, we are interested in drawing a line/curve on an x and y axis that can summarize the trend of the dataset. The line is represented as $y = a X + b$. Here \\textit{X} is the feature matrix while \\textit{y} is the target or label. Specifically, we want to learn the gradient $a$ and intercept $b$. Thus, when creating the Linear Regression model, we have to specify the parameter \\textit{fit\\_intercept} to be true. Let's create our model instance:\n\\begin{lstlisting}[language=Python]\nmodel = LinearRegression(fit_intercept=True)\n\\end{lstlisting}\n\nNow, we have created the model, but we haven't passed any data to it.\n\n\\subsubsection*{Arrange data into a features matrix and target vector.}\nNote: In this example, we are passing the data to the Scikit-Learn library as NumPy. In later exercise, we will use pandas.\\\\\n\nWe have discussed previosuly the data representation that Scikit-Learn expects when passing data to the model. At this stage, we already have the target \\textit{y} in good shape (length of \\textit{n\\_samples}), but we need to reshape the features to be two-dimenstional. At the moment, we have \\textit{x} with shape [50]. Here is how we can reshape it to be two-dimensional:\n\\begin{lstlisting}[language=Python]\nX = x.reshape(len(x), 1)\n\\end{lstlisting}\n\nAlright, now we are ready to pass the data to the model for training.\n\n\\subsubsection*{Fit the model to your data.}\nWe pass the data to the model for training by using the \\textit{fit()} function:\n\\begin{lstlisting}[language=Python]\nmodel.fit(X, y)\n\\end{lstlisting}\n\nThe call to the \\textit{fit} function causes many internal computation to infer the gradient and intercept. For this course, you don't have to worry about what happened in the background. In later courses, you will be able to understand the math behind it and how to build other types and more complex models.\n\nNow, if we want to check the gradient and intercept learned, we can print them. To access an attribute of the class instance in Scikit-Learn, we use a trailing underscore:\n\\begin{lstlisting}[language=Python]\nmodel.coef_\n\\end{lstlisting}\nOutput:\n\\begin{lstlisting}[language=Python]\narray([ 1.9776566])\n\\end{lstlisting}\n\n\\begin{lstlisting}[language=Python]\nmodel.intercept_\n\\end{lstlisting}\nOutput:\n\\begin{lstlisting}[language=Python]\n-0.9033107255311164\n\\end{lstlisting}\n\n\\subsubsection*{Predict labels for unknown data.}\nOnce the model is trained, we can start performing some prediction. This is why we are learning about Machine Learning, right? We want to pass the model data and see what decision it will make. We can do this using the \\textit{predict()} function of the Linear Regression class.\n\nLet's create some data to preform prediction on. We can use the \\textit{linespace()} of the numpy library to create a sequence of numbers that are equally spaced:\n\n\\begin{lstlisting}[language=Python]\nxfit = np.linspace(-1, 11)\n\\end{lstlisting}\n\n\\textbf{As we did before, we have to reshape the data before passing it to the model for prediction. Remember this step very well, because if we do any kind of preprocessing to the data before we pass it for training, we have to repeat that again before prediction}. Now, lets do some prediction:\n\\begin{lstlisting}[language=Python]\nXfit = xfit.reshape(len(x), 1)\nyfit = model.predict(Xfit)\n\\end{lstlisting}\n\nAfter we run the code, we get \\textit{yfit}, which are our predictions. Now let's plot our data and the predictions using matplotlib:\n\\begin{lstlisting}[language=Python]\nplt.scatter(x, y)\nplt.plot(xfit, yfit);\n\\end{lstlisting}\nHere is what we get:\n\n\\begin{figure}[htp!]\n    \\centering\n    \\includegraphics[scale=0.8]{Images/prediction.png}\n\\end{figure}", "metadata": {"source": "./full-course/aai.txt"}}}